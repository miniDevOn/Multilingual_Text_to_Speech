{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import IPython.display\n",
    "\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from collections import Counter, OrderedDict\n",
    "from torchsummary import summary\n",
    "\n",
    "# load other modules --> repo root path\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import torch\n",
    "from utils import text, audio\n",
    "from utils.logging import Logger\n",
    "from params.params import Params as hp\n",
    "from modules.tacotron2 import Tacotron\n",
    "from dataset.dataset import TextToSpeechDataset, TextToSpeechDatasetCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.sample_rate = 22050\n",
    "hp.stft_window_ms = 50\n",
    "hp.stft_shift_ms = 12.5\n",
    "hp.num_fft = 1102\n",
    "hp.num_mels = 80\n",
    "hp.use_preemphasis = True\n",
    "\n",
    "#waveform = audio.load(\"../data/vctk/wav48/p226/p226_012.wav\")\n",
    "waveform = audio.load(\"../data/ljspeech/wavs/LJ002-0001.wav\")\n",
    "print(audio.duration(waveform))\n",
    "\n",
    "melspec = audio.mel_spectrogram(waveform)\n",
    "spec = audio.spectrogram(waveform)\n",
    "\n",
    "Logger._plot_spectrogram(melspec);\n",
    "Logger._plot_spectrogram(spec);\n",
    "\n",
    "print(spec.shape)\n",
    "print(melspec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=waveform, rate=hp.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.griffin_lim_iters = 60\n",
    "\n",
    "inverse_melspec = audio.inverse_mel_spectrogram(melspec)\n",
    "IPython.display.Audio(data=inverse_melspec, rate=hp.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.griffin_lim_iters = 60\n",
    "\n",
    "inverse_melspec = audio.inverse_spectrogram(spec)\n",
    "IPython.display.Audio(data=inverse_melspec, rate=hp.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.griffin_lim_iters = 60\n",
    "\n",
    "y = waveform\n",
    "if hp.use_preemphasis: y = scipy.signal.lfilter([1, -hp.preemphasis], [1], y)\n",
    "wf = int(hp.sample_rate * hp.stft_window_ms / 1000)\n",
    "hf = int(hp.sample_rate * hp.stft_shift_ms / 1000)\n",
    "S = librosa.stft(y, n_fft=hp.num_fft , hop_length=hf, win_length=wf)\n",
    "y = librosa.istft(S, hop_length=hf, win_length=wf)\n",
    "if hp.use_preemphasis: y = scipy.signal.lfilter([1], [1, -hp.preemphasis], y)\n",
    "\n",
    "IPython.display.Audio(data=y, rate=hp.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.griffin_lim_iters = 60\n",
    "\n",
    "SS = librosa.amplitude_to_db(np.abs(S), top_db=None)\n",
    "inverse_melspec = audio.inverse_spectrogram(SS)\n",
    "IPython.display.Audio(data=inverse_melspec, rate=hp.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logger._plot_spectrogram(np.angle(S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dataparallel_prefix(state_dict): \n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:]\n",
    "        new_state_dict[name] = v\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(checkpoint):   \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    state = torch.load(checkpoint, map_location=device)\n",
    "    hp.load_state_dict(state['parameters'])\n",
    "    model = Tacotron()\n",
    "    model.load_state_dict(remove_dataparallel_prefix(state['model']))   \n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model):\n",
    "    \n",
    "\n",
    "    spectrograms = []\n",
    "    for i in inputs:\n",
    "        i = torch.LongTensor(text.to_sequence(i, use_phonemes=hp.use_phonemes))\n",
    "        if torch.cuda.is_available(): i = i.cuda(non_blocking=True)\n",
    "        spectrograms.append(model.inference(i).cpu().detach().numpy())\n",
    "        \n",
    "    return spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = \"../checkpoints/DEUTSCH-GA_loss-299-0.265\"\n",
    "checkpoint = \"../checkpoints/BASE_loss-299-0.191\"\n",
    "# checkpoint = \"../checkpoints/JAPAN_loss-319-0.254\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(checkpoint)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\"sumimasen 。\",\n",
    "          \"kon nichiwa 、genkidesuka ?\",\n",
    "          \"kocchi no ko-i wo uketoru toki 、 aite no yari kane nai gyo-san na aisatsu mo azayaka ni egakidasa re ta \",\n",
    "          \"dobry den 、 ja jsem z nemecka 。\",\n",
    "          \"Dobry den, ja jsem z Nemecka, prd prd prd.\",\n",
    "          \"Hello, it is me. I am from Germany.\",\n",
    "          \"He has agreed a deal with the EU but the bill implementing it has been put on hold.\",\n",
    "          \"Just returned to the United States after spending a great Thanksgiving with our Courageous American Warriors in Afghanistan!\",\n",
    "          \"President of the United States of America, by virtue of the authority vested in me by the Constitution and the laws of the United States, do hereby proclaim Thursday, as a National Day of Thanksgiving.\",\n",
    "          \"Guten Tag, wie geht es dir?\",\n",
    "          \"Es geht mir gut, danke.\",\n",
    "          \"Erlauben Sie bitte, dass ich mich kurz vorstelle. Ich heiße Jana Novakova.\",\n",
    "          \"Ein aktueller Bericht der Bundesnetzagentur zeigt, dass die Preise an der Strombörse deutlich steigen.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_spectrograms = inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.griffin_lim_iters = 60\n",
    "hp.griffin_lim_power = 1.45\n",
    "\n",
    "for i, s in enumerate(generated_spectrograms):\n",
    "    s = audio.denormalize_spectrogram(s, not hp.predict_linear)\n",
    "    w = audio.inverse_spectrogram(s, not hp.predict_linear)\n",
    "    a = IPython.display.Audio(data=w, rate=hp.sample_rate)\n",
    "    IPython.display.display(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
