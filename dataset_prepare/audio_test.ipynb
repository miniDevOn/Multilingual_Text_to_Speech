{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import IPython.display\n",
    "\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "# load other modules --> repo root path\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import torch\n",
    "from utils import text, audio\n",
    "from utils.logging import Logger\n",
    "from params.params import Params as hp\n",
    "from modules.tacotron2 import Tacotron\n",
    "from dataset.dataset import TextToSpeechDataset, TextToSpeechDatasetCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dataparallel_prefix(state_dict): \n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:]\n",
    "        new_state_dict[name] = v\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(checkpoint):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    state = torch.load(checkpoint, map_location=device)\n",
    "    hp.load_state_dict(state['parameters'])\n",
    "\n",
    "    model = Tacotron()\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = remove_dataparallel_prefix(state['model'])\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    \n",
    "    model_dict.update(pretrained_dict) \n",
    "    model.load_state_dict(model_dict) \n",
    "    model.to(device)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, inputs):\n",
    "    \n",
    "    inputs = [l.rstrip().split('|') for l in inputs if l]\n",
    "\n",
    "    spectrograms = []\n",
    "    for i in inputs:\n",
    "        t = torch.LongTensor(text.to_sequence(i[0], use_phonemes=hp.use_phonemes))\n",
    "        l = torch.LongTensor([hp.languages.index(i[2])]) if hp.multi_language else None\n",
    "        s = torch.LongTensor([hp.unique_speakers.index(i[1])]) if hp.multi_speaker else None\n",
    "\n",
    "        if torch.cuda.is_available(): \n",
    "            t = t.cuda(non_blocking=True)\n",
    "            if l: l = l.cuda(non_blocking=True)\n",
    "            if s: s = s.cuda(non_blocking=True)\n",
    "                \n",
    "        spectrograms.append(model.inference(t, speaker=s, language=l).cpu().detach().numpy())\n",
    "\n",
    "    return spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint = \"../checkpoints/FRGE2B_loss-129-0.085\"\n",
    "checkpoint = \"../checkpoints/pretrain/CSS-ACU_loss-99-0.145\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(checkpoint, map_location=\"cpu\")['parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(checkpoint)\n",
    "model.eval();\n",
    "print(hp.encoder_type)\n",
    "print(hp.encoder_dimension)\n",
    "print(hp.languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\"erlauben sie bitte, dass ich mich kurz vorstelle. ich heiße jana novakova.||hungarian\",\n",
    "          \"les socialistes et les républicains sont venus apporter leurs voix à la majorité pour ce texte.||spanish\",\n",
    "          \"and when the first municipal authority of our land will be no longer subjected to the reproach||german\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_spectrograms = inference(model, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in enumerate(generated_spectrograms):\n",
    "    s = audio.denormalize_spectrogram(s, not hp.predict_linear)\n",
    "    w = audio.inverse_spectrogram(s, not hp.predict_linear)\n",
    "    a = IPython.display.Audio(data=w, rate=hp.sample_rate)\n",
    "    IPython.display.display(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaning language embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.layers import ConstantEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = model._decoder._language_embedding.weight[1,:] # .mean(dim=0)\n",
    "model._decoder._language_embedding = ConstantEmbedding(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_spectrograms = inference(model, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in enumerate(generated_spectrograms):\n",
    "    s = audio.denormalize_spectrogram(s, not hp.predict_linear)\n",
    "    w = audio.inverse_spectrogram(s, not hp.predict_linear)\n",
    "    a = IPython.display.Audio(data=w, rate=hp.sample_rate)\n",
    "    IPython.display.display(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
