{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import IPython.display\n",
    "\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "\n",
    "# load other modules --> repo root path\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from utils import text\n",
    "from utils import audio\n",
    "from utils.logging import Logger\n",
    "from params.params import Params as hp\n",
    "from dataset.dataset import TextToSpeechDataset, TextToSpeechDatasetCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.sample_rate = 22050\n",
    "hp.stft_window_ms = 50\n",
    "hp.stft_shift_ms = 12.5\n",
    "hp.num_fft = 1102\n",
    "hp.num_mels = 80\n",
    "hp.use_preemphasis = True\n",
    "\n",
    "#waveform = audio.load(\"../data/vctk/wav48/p226/p226_012.wav\")\n",
    "waveform = audio.load(\"../data/ljspeech/wavs/LJ002-0001.wav\")\n",
    "print(audio.duration(waveform))\n",
    "\n",
    "melspec = audio.mel_spectrogram(waveform)\n",
    "spec = audio.spectrogram(waveform)\n",
    "\n",
    "Logger._plot_spectrogram(melspec);\n",
    "Logger._plot_spectrogram(spec);\n",
    "\n",
    "print(spec.shape)\n",
    "print(melspec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=waveform, rate=hp.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.griffin_lim_iters = 60\n",
    "\n",
    "inverse_melspec = audio.inverse_mel_spectrogram(melspec)\n",
    "IPython.display.Audio(data=inverse_melspec, rate=hp.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.griffin_lim_iters = 60\n",
    "\n",
    "inverse_melspec = audio.inverse_spectrogram(spec)\n",
    "IPython.display.Audio(data=inverse_melspec, rate=hp.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.griffin_lim_iters = 60\n",
    "\n",
    "y = waveform\n",
    "if hp.use_preemphasis: y = scipy.signal.lfilter([1, -hp.preemphasis], [1], y)\n",
    "wf = int(hp.sample_rate * hp.stft_window_ms / 1000)\n",
    "hf = int(hp.sample_rate * hp.stft_shift_ms / 1000)\n",
    "S = librosa.stft(y, n_fft=hp.num_fft , hop_length=hf, win_length=wf)\n",
    "y = librosa.istft(S, hop_length=hf, win_length=wf)\n",
    "if hp.use_preemphasis: y = scipy.signal.lfilter([1], [1, -hp.preemphasis], y)\n",
    "\n",
    "IPython.display.Audio(data=y, rate=hp.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.griffin_lim_iters = 60\n",
    "\n",
    "SS = librosa.amplitude_to_db(np.abs(S), top_db=None)\n",
    "inverse_melspec = audio.inverse_spectrogram(SS)\n",
    "IPython.display.Audio(data=inverse_melspec, rate=hp.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logger._plot_spectrogram(np.angle(S))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
